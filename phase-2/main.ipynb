{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals\n",
    "from numpy.core.numeric import NaN\n",
    "from regex.regex import escape\n",
    "from collections import Counter\n",
    "import regex, copy, heapq, math, operator, random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys,os,sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install hazm\n",
    "from hazm import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_links = pd.read_csv('IR_Spring2021_ph12_7k.csv')\n",
    "docs_links = docs_links[docs_links['content'].notnull()]\n",
    "\n",
    "documents = pd.read_csv('IR_Spring2021_ph12_7k.csv').iloc[:,1].values.tolist()\n",
    "links = pd.read_csv('IR_Spring2021_ph12_7k.csv').iloc[:,2].values.tolist()\n",
    "\n",
    "punctuations = pd.read_csv(\"punctuations.csv\")\n",
    "punctuations_to_remove = ''.join(punctuations[\"punctuations\"].values.tolist()).replace(\" \",\"\")\n",
    "stopwords_to_remove = ''.join(stopwords_list()).replace(\" \",\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = Normalizer()\n",
    "lemmatizer = Lemmatizer()\n",
    "N=len(docs_links[\"content\"])\n",
    "docs_len = {}\n",
    "\n",
    "def tokenize(id, document):\n",
    "    document = str(document)\n",
    "    document = document.replace(\"انتهای پیام\",\"\")\n",
    "    n_document = str(normalizer.normalize(document))\n",
    "    #remove punctuations\n",
    "    n_document = n_document.translate(str.maketrans('','',punctuations_to_remove))\n",
    "    #remove stop words\n",
    "    tokens = list(map(lambda t:lemmatizer.lemmatize(t),word_tokenize(n_document))) \n",
    "    dictionary = dict(Counter(tokens))\n",
    "    for k, tf in dictionary.items():\n",
    "        dictionary[k] = 1 + math.log10(tf)\n",
    "    if id is not None:\n",
    "        docs_len[id] = dictionary\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Weighted Inverted Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_weighted_inv_ind(docs_links):\n",
    "    dictionary = {}\n",
    "    for id, doc in zip(docs_links[\"id\"], docs_links[\"content\"]):\n",
    "        counts = tokenize(id, doc)\n",
    "        for k,v in counts.items():\n",
    "            if len(k) < 3:\n",
    "                continue\n",
    "            if k in dictionary.keys():\n",
    "                dictionary[k][0] += 1\n",
    "                dictionary[k][1][id] = v\n",
    "            else:\n",
    "                dictionary[k]=[1,{id:v}]\n",
    "    # calc idfs \n",
    "    for k in dictionary.keys():\n",
    "        dictionary[k][0] = math.log10(N/dictionary[k][0])\n",
    "    \n",
    "    for id, dl in docs_len.items():\n",
    "        size_d = 0\n",
    "        for t, w in dl.items():\n",
    "            if t in dictionary:\n",
    "                size_d += dictionary[t][0]*w\n",
    "        docs_len[id] = math.sqrt(size_d)\n",
    "    return dictionary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Champion Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_champion_lists(weighted_inv_ind):\n",
    "    champion_lists = {}\n",
    "    for t, ws in weighted_inv_ind.items():\n",
    "        champion_lists[t] = []\n",
    "        champion_lists[t].append(ws[0])\n",
    "        champion_lists[t].append(dict(sorted(ws[1].items(), key=operator.itemgetter(1), reverse=True)[:10]))\n",
    "    return champion_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.82 s, sys: 57.3 ms, total: 5.87 s\n",
      "Wall time: 5.88 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "weighted_inv_ind = build_weighted_inv_ind(docs_links)\n",
    "champion_lists = build_champion_lists(weighted_inv_ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=len(docs_links[\"content\"])\n",
    "def compute_similarity(nd_q, weighted_inv_ind):\n",
    "    similarities = {}\n",
    "    for k,v in nd_q.items():\n",
    "        if k not in weighted_inv_ind:\n",
    "            continue\n",
    "        #idf = math.log(N/weighted_inv_ind[k][0])\n",
    "        idf = weighted_inv_ind[k][0]\n",
    "        for docid, w in weighted_inv_ind[k][1].items():\n",
    "            if docid in similarities.keys():\n",
    "                similarities[docid] += idf*w*(1+math.log10(v))\n",
    "            else:\n",
    "                similarities[docid] = idf*w*v\n",
    "    for doc_id, sim in similarities.items():\n",
    "        similarities[doc_id] = sim/docs_len[doc_id]\n",
    "    return similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the best scores by calculating the most similar indexes to the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k_most_sim(query, weighted_inv_ind, use_heap, k=5):\n",
    "    scores = compute_similarity(tokenize(None, query), weighted_inv_ind)\n",
    "    best_scores =[]\n",
    "    heap = []\n",
    "    if use_heap == True:\n",
    "        for docid,score in scores.items():\n",
    "            heapq.heappush(heap,(-score, docid))\n",
    "        for _ in range(k):\n",
    "            best_scores.append(heapq.heappop(heap))\n",
    "    else:\n",
    "        best_scores = {k: v for k, v in sorted(scores.items(), key=lambda item: item[1], reverse = True)}\n",
    "        best_scores = list(best_scores)[:k]\n",
    "    return best_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links(top_k, docs_links, use_heap):\n",
    "    results=[]\n",
    "    if use_heap == True:\n",
    "        for i in top_k:\n",
    "            results.append(docs_links.loc[docs_links.index[docs_links['id'] == i[1]].tolist()[0]][\"url\"])\n",
    "    else:\n",
    "        for i in top_k:\n",
    "            results.append(docs_links.loc[docs_links.index[docs_links['id'] == i].tolist()[0]][\"url\"])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A few examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-0.469636181566958, 6458),\n",
       " (-0.469636181566958, 6464),\n",
       " (-0.45463906624891315, 6408),\n",
       " (-0.4460984032732113, 5964),\n",
       " (-0.40550846405575436, 6005),\n",
       " (-0.38370132008348123, 149)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k = get_k_most_sim(\"واکسیناسیون بیماری کرونا در جهان\", weighted_inv_ind, True, 6)\n",
    "top_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.isna.ir/news/99120705273/آغاز-واکسیناسیون-سالمندان-و-جانبازان-آسایشگاه-ها-علیه-کووید-۱۹-عکس',\n",
       " 'https://www.isna.ir/news/99120705273/آغاز-واکسیناسیون-سالمندان-و-جانبازان-آسایشگاه-ها-علیه-کووید-۱۹-عکس',\n",
       " 'https://www.isna.ir/news/99112014708/واکسن-کرونا-کی-به-استان-مرکزی-می-رسد',\n",
       " 'https://www.isna.ir/news/99061510873/کاهش-پوشش-واکسیناسیون-کودکان-در-کشور-تحت-تاثیر-کرونا',\n",
       " 'https://www.isna.ir/news/99062519519/آیا-موج-سوم-کرونا-در-کشور-آغاز-می-شود-یا-خیر',\n",
       " 'https://www.isna.ir/news/99030804393/قهرمان-کشتی-المپیک-کرونا-گرفت']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_links(top_k, docs_links, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.isna.ir/news/98070201774/بررسی-طرح-اصلاح-قانون-پرداخت-تسهیلات-اشتغال-زایی-روستائیان-در',\n",
       " 'https://www.isna.ir/news/98070201774/بررسی-طرح-اصلاح-قانون-پرداخت-تسهیلات-اشتغال-زایی-روستائیان-در',\n",
       " 'https://www.isna.ir/news/98070907368/تعویق-سه-ساله-بازگشت-تسهیلات-اشتغال-روستایی-و-عشایری',\n",
       " 'https://www.isna.ir/news/98041005289/صندوق-کارآفرینی-امید-امسال-۱۰۰-هزار-شغل-ایجاد-می-کند',\n",
       " 'https://www.isna.ir/news/98031807669/کندی-آهنگ-پرداخت-تسهیلات-از-سوی-بانک-های-کرمانشاه',\n",
       " 'https://www.isna.ir/news/98050502291/حذف-یارانه-دهک-های-پردرآمد-کلید-خورد']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k = get_k_most_sim(\"وام‌های اشتغال‌زایی عشایری و روستایی\", weighted_inv_ind, True, 6)\n",
    "get_links(top_k, docs_links, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.isna.ir/news/98020201014/اعضای-کمیسیون-برنامه-از-سامانه-سنا-بازدید-کردند',\n",
       " 'https://www.isna.ir/news/98121008034/آغاز-ثبت-اعتراض-حذف-شدگان-مسکن-ملی-از-امروز',\n",
       " 'https://www.isna.ir/news/98081911066/جزئیات-برخورداری-از-یارانه-دولتی-بیمه-تکلیف-بیمه-مردم-باید-روشن',\n",
       " 'https://www.isna.ir/news/99121108369/هزینه-۱۱۰-میلیاردی-بستری-و-درمان-بیماران-کرونا-در-بوشهر',\n",
       " 'https://www.isna.ir/news/99091007815/گزارش-رئیس-سازمان-بیمه-سلامت-در-کمیسیون-بهداشت',\n",
       " 'https://www.isna.ir/news/99080301248/بیمارستان-شهدای-هسته-ای-بوشهر-در-مراحل-پایانی-تکمیل-است']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k = get_k_most_sim(\"پرونده الکترونیک سلامت\", weighted_inv_ind, True, 6)\n",
    "get_links(top_k, docs_links, True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('mlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4976e0179d97dd6d59b1329a76e601e17b789c2571b41c8b57f5fd69821c0dd3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
