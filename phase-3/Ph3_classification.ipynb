{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals\n",
    "from numpy.core.numeric import NaN\n",
    "from collections import Counter\n",
    "from regex.regex import escape\n",
    "import regex, copy, heapq, math, operator, random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys,os,sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install hazm\n",
    "from hazm import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_links = pd.read_csv('IR00_3_11k News.csv')\n",
    "unlabeled = pd.read_csv('IR_Spring2021_ph12_7k.csv')\n",
    "docs_links = docs_links[docs_links['content'].notnull()]\n",
    "\n",
    "documents = pd.read_csv('IR_Spring2021_ph12_7k.csv').iloc[:,1].values.tolist()\n",
    "links = pd.read_csv('IR_Spring2021_ph12_7k.csv').iloc[:,2].values.tolist()\n",
    "\n",
    "punctuations = pd.read_csv(\"punctuations.csv\")\n",
    "punctuations_to_remove = ''.join(punctuations[\"punctuations\"].values.tolist()).replace(\" \",\"\")\n",
    "stopwords_to_remove = ''.join(stopwords_list()).replace(\" \",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [pd.read_csv('IR00_3_11k News.csv'), pd.read_csv('IR00_3_17k News.csv'), pd.read_csv('IR00_3_20k News.csv')]\n",
    "offset=int(files[0].tail(1)[\"id\"])\n",
    "files[1][\"id\"]=files[1][\"id\"]+offset\n",
    "offset=int(files[1].tail(1)[\"id\"])\n",
    "files[2][\"id\"]=files[2][\"id\"]+offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('IR00_3_11k News.csv')\n",
    "data[\"topic\"].replace({\"political\": \"politics\", \"sport\": \"sports\"}, inplace=True)\n",
    "data=pd.concat(files)\n",
    "data.index=data.id\n",
    "data = data[data['content'].notnull()]\n",
    "docs_links = data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = Normalizer()\n",
    "lemmatizer = Lemmatizer()\n",
    "N=len(docs_links[\"content\"])\n",
    "docs_len = {}\n",
    "\n",
    "def tokenize(id, document):\n",
    "    document = str(document)\n",
    "    document = document.replace(\"انتهای پیام\",\"\")\n",
    "    n_document = str(normalizer.normalize(document))\n",
    "    #remove punctuations\n",
    "    n_document = n_document.translate(str.maketrans('','',punctuations_to_remove))\n",
    "    #remove stop words\n",
    "    tokens = list(map(lambda t:lemmatizer.lemmatize(t),word_tokenize(n_document))) \n",
    "    if id is not None:\n",
    "        docs_len[id] = len(tokens)\n",
    "    dictionary = dict(Counter(tokens))\n",
    "    for k, tf in dictionary.items():\n",
    "        dictionary[k] = 1 + math.log10(tf)\n",
    "    \n",
    "    if id is not None:\n",
    "        docs_len[id] = dictionary\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Weighted Inverted Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_weighted_inv_ind(docs_links):\n",
    "    dictionary = {}\n",
    "    for id, doc in zip(docs_links[\"id\"], docs_links[\"content\"]):\n",
    "        counts = tokenize(id, doc)\n",
    "        for k,v in counts.items():\n",
    "            if len(k) < 3:\n",
    "                continue\n",
    "            if k in dictionary.keys():\n",
    "                dictionary[k][0] += 1\n",
    "                dictionary[k][1][id] = v\n",
    "            else:\n",
    "                dictionary[k]=[1,{id:v}]\n",
    "    # calc idfs \n",
    "    for k in dictionary.keys():\n",
    "        dictionary[k][0] = math.log10(N/dictionary[k][0])\n",
    "    \n",
    "    for id, dl in docs_len.items():\n",
    "        size_d = 0\n",
    "        for t, w in dl.items():\n",
    "            if t in dictionary:\n",
    "                size_d += dictionary[t][0]*w\n",
    "        docs_len[id] = math.sqrt(size_d)\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_inv_ind = build_weighted_inv_ind(docs_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build document term frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_doc_term_feq(docs_links):\n",
    "    dictionary = {}\n",
    "    for id, doc in zip(docs_links[\"id\"], docs_links[\"content\"]):\n",
    "        counts = tokenize(None, doc)\n",
    "        dictionary[id] = counts\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled = build_doc_term_feq(unlabeled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-nearest neighbors (knn) classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=len(docs_links[\"content\"])\n",
    "def do_knn(doc_toks, weighted_inv_ind, k=5):\n",
    "    similarities = {}\n",
    "    for t,v in doc_toks.items():\n",
    "        if t not in weighted_inv_ind:\n",
    "            continue\n",
    "        idf = weighted_inv_ind[t][0]\n",
    "        for docid, w in weighted_inv_ind[t][1].items():\n",
    "            if docid in similarities.keys():\n",
    "                similarities[docid] += idf*w*v\n",
    "            else:\n",
    "                similarities[docid] = idf*w*v\n",
    "    for doc_id, sim in similarities.items():\n",
    "        similarities[doc_id] = sim/docs_len[doc_id]\n",
    "    \n",
    "    scores = similarities\n",
    "    if len(scores) < k:\n",
    "        k = len(scores)\n",
    "    best_scores =[]\n",
    "    heap = []\n",
    "    for docid,score in scores.items():\n",
    "        heapq.heappush(heap,(-score, docid))\n",
    "    for _ in range(k):\n",
    "        best_scores.append(heapq.heappop(heap))\n",
    "    cats = []\n",
    "    for doc in best_scores:\n",
    "        doc_id = doc[1]\n",
    "        cat = docs_links.loc[docs_links.index[docs_links['id'] == doc_id].tolist()[0]][\"topic\"]\n",
    "        cats.append(cat)\n",
    "    if len(cats) == 0:\n",
    "        return 'none'\n",
    "    return max(set(cats), key=cats.count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled = {}\n",
    "c = 0\n",
    "for id, doc in unlabeled.items():\n",
    "    labeled[id] = do_knn(doc, weighted_inv_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49856"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'sports': 1664,\n",
       "         'health': 1474,\n",
       "         'culture': 147,\n",
       "         'politics': 1558,\n",
       "         'economy': 2153,\n",
       "         'none': 4})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rplc = {\"political\": \"politics\", \"sport\": \"sports\"}\n",
    "labeled = {k: rplc.get(v, v) for k, v in labeled.items()}\n",
    "cats = Counter(labeled.values())\n",
    "cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'economy'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_links.loc[docs_links.index[docs_links['id'] == 5412].tolist()[0]][\"topic\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "unlabeled = pd.read_csv('IR_Spring2021_ph12_7k.csv')\n",
    "df = copy.deepcopy(unlabeled)\n",
    "df['topic'] = df['id'].map(labeled)\n",
    "df.to_csv('IR_Spring2021_ph12_7k_labeled.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(labeled.items())\n",
    "df.columns = ['id', 'topic']\n",
    "df.to_csv('IR_Spring2021_ph12_7k_labeled.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=len(docs_links[\"content\"])\n",
    "def compute_similarity(nd_q, weighted_inv_ind, picked_docs):\n",
    "    similarities = {}\n",
    "    for k,v in nd_q.items():\n",
    "        if k not in weighted_inv_ind:\n",
    "            continue\n",
    "        idf = weighted_inv_ind[k][0]\n",
    "        for docid, w in weighted_inv_ind[k][1].items():\n",
    "            if docid not in picked_docs:\n",
    "                continue\n",
    "            if docid in similarities.keys():\n",
    "                similarities[docid] += idf*w*v\n",
    "            else:\n",
    "                similarities[docid] = idf*w*v\n",
    "    for doc_id, sim in similarities.items():\n",
    "        similarities[doc_id] = sim/docs_len[doc_id]\n",
    "    return similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the best scores by calculating the most similar indexes to the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k_most_sim(query, weighted_inv_ind, picked_docs, k=5):\n",
    "    scores = compute_similarity(tokenize(None, query), weighted_inv_ind, picked_docs)\n",
    "    best_scores =[]\n",
    "    heap = []\n",
    "    for docid,score in scores.items():\n",
    "        heapq.heappush(heap,(-score, docid))\n",
    "    if len(heap) < k:\n",
    "        k = len(heap)\n",
    "    for _ in range(k):\n",
    "        best_scores.append(heapq.heappop(heap))\n",
    "    return best_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def answer_query(query, df, k):\n",
    "    q_toks = re.split(' ', query)\n",
    "    topic = q_toks[0][4:]\n",
    "    filtered_df = df[df['topic'] == topic]\n",
    "    picked_docs = filtered_df['id'].tolist()\n",
    "    \n",
    "    answer = get_k_most_sim(query, weighted_inv_ind, picked_docs, k)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links(top_k, docs_links):\n",
    "    results=[]\n",
    "    for i in top_k:\n",
    "        results.append(docs_links.loc[docs_links.index[docs_links['id'] == i[1]].tolist()[0]][\"url\"])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('IR_Spring2021_ph12_7k_labeled.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-0.3262301921084849, 915),\n",
       " (-0.30892837434627746, 1480),\n",
       " (-0.3065800814325119, 801),\n",
       " (-0.30161753103948996, 418),\n",
       " (-0.29989379038081343, 920)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k = answer_query('cat:sports استقلال', df,5)\n",
    "top_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.isna.ir/news/99111309632/شکایت-استقلال-در-کمیته-انضباطی-فدراسیون-کشتی-بررسی-می-شود',\n",
       " 'https://www.isna.ir/news/98090805350/حضور-فتحی-در-اردوی-استقلال-پیش-از-بازی-با-سپاهان-آبی-ها-پاداش',\n",
       " 'https://www.isna.ir/news/99100805979/استقلال-وارد-لیگ-برتر-تکواندو-شد',\n",
       " 'https://www.isna.ir/news/99060605427/جلسه-فوری-کادر-مدیریتی-استقلال-برای-استعفای-مجیدی',\n",
       " 'https://www.isna.ir/news/99111511845/پنجره-نقل-و-انتقالات-باشگاه-استقلال-بسته-شد']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_links(top_k, docs_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'economy'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled[75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.isna.ir/news/99082315432/واکسن-های-ایرانی-کرونا-در-فهرست-کاندیداهای-واکسن-سازمان-بهداشت',\n",
       " 'https://www.isna.ir/news/99041108441/تعطیلی-بازارهای-سرپوشیده-در-۴-شهرستان-استان-بوشهر',\n",
       " 'https://www.isna.ir/news/99010200782/تکذیب-یک-ادعا-درباره-جانباختگان-کرونا-در-ایران',\n",
       " 'https://www.isna.ir/news/99092821716/کاهش-موارد-بستری-به-۷۵-بیمار-ثبت-یک-روز-بدون-فوتی-کرونا',\n",
       " 'https://www.isna.ir/news/99050100731/اعلام-اسامی-مراکز-غربالگری-کرونا-در-استان-تهران']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k = answer_query('cat:health کرونا', df,5)\n",
    "get_links(top_k, docs_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.isna.ir/news/99061309882/تکذیب-شایعه-ابتلای-آیت-الله-جنتی-به-کرونا',\n",
       " 'https://www.isna.ir/news/99050806366/لاریجانی-دوباره-کرونا-گرفت',\n",
       " 'https://www.isna.ir/news/99091108977/چنارانی-و-دلخوش-به-کرونا-مبتلا-شدند',\n",
       " 'https://www.isna.ir/news/99011608234/محمدرضا-خاتمی-از-بیمارستان-مرخص-شد',\n",
       " 'https://www.isna.ir/news/99041410245/زاهدی-از-بیمارستان-مرخص-شد']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k = answer_query('cat:politics کرونا', df,5)\n",
    "get_links(top_k, docs_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.isna.ir/news/99010703339/تزریق-بیش-از-۳۸۳۳-میلیارد-تومان-دیگر-توسط-دولت-به-نظام-سلامت',\n",
       " 'https://www.isna.ir/news/99021410064/کرونا-پشت-ثروتمندترین-کشورهای-دنیا-را-خم-کرده-است',\n",
       " 'https://www.isna.ir/news/99022013695/کاهش-۵۰-درصدی-حقوق-کارمندان-اتحادیه-جهانی-کشتی',\n",
       " 'https://www.isna.ir/news/99031911937/بازگشت-جمعی-از-ایرانیان-مقیم-قزاقستان-با-پرواز-فوق-العاده-به',\n",
       " 'https://www.isna.ir/news/99060906501/چین-نخستین-اقتصادی-که-از-کرونا-عبور-کرد']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k = answer_query('cat:economy کرونا', df,5)\n",
    "get_links(top_k, docs_links)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('mlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4976e0179d97dd6d59b1329a76e601e17b789c2571b41c8b57f5fd69821c0dd3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
